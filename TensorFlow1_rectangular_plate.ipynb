{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WAN_example1_2d.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMQO5O5xCINAZKg4fs8ZKhZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"TlXTg6-dlcMA","executionInfo":{"status":"ok","timestamp":1602847933422,"user_tz":-480,"elapsed":1483,"user":{"displayName":"Rainie Zhang","photoUrl":"","userId":"00518680448560906167"}}},"source":["import os\n","os.environ[\"CUDA_DEVICES_ORDER\"]= \"PCI_BUS_IS\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n","\n","class pde_wan():\n","    \n","    def __init__(self, dim=2):\n","        import numpy as np\n","        global np\n","        #\n","        import time\n","        global time\n","        #\n","        #import tensorflow as tf\n","        import tensorflow.compat.v1 as tf\n","        global tf\n","        tf.disable_v2_behavior()\n","        #\n","        import matplotlib.pyplot as plt\n","        global plt\n","        #\n","        from scipy.interpolate import griddata\n","        global griddata\n","        #\n","        self.up= 1.0\n","        self.low= 0\n","        \n","        self.mesh_size= 256\n","        #\n","        self.v_layer= 6\n","        self.v_hidden_size= 50\n","        self.v_step= 1       \n","        self.v_rate=0.015   \n","        self.u_layer= 6\n","        self.u_hidden_size= 20\n","        self.u_step= 1\n","        self.u_rate=0.015\n","        self.batch_size= 20000 \n","        self.test_size=  5000\n","        self.bound_size= 100#(*2*dim)\n","        self.iteration=  20001\n","        self.dim= dim \n","        self.dir= './problem_weak/'\n","    def sample_train(self, dm_size, bd_size, dim):      ##dm-domain;bd-boundry;dim-dimension\n","        low= self.low; up= self.up;\n","        #*********************************************************\n","        # collocation points in domain\n","        x_dm= np.random.uniform(low, up, [dm_size, dim]) ##up=1;low=0;dim=2\n","        \n","        #*********************************************************\n","        # collocation points on boundary\n","        x_bd_list=[]  #x_boundry\n","        for i in range(dim):\n","            x_bound= np.random.uniform(low, up, [bd_size, dim])\n","            x_bound[:,i]= up\n","            x_bd_list.append(x_bound)\n","            x_bound= np.random.uniform(low, up, [bd_size, dim])\n","            x_bound[:,i]= low\n","            x_bd_list.append(x_bound)\n","        x_bd= np.concatenate(x_bd_list, axis=0)\n","        \n","        #*********************************************************\n","        int_dm= (up-low)**dim        ##integrate domain\n","        #*********************************************************\n","        f_dm=np.ones([dm_size,1])\n","        for i in range(dm_size):\n","          f_dm[i]=1\n","      \n","        #*********************************************************\n","        # u(x) on boundary\n","        x= np.reshape(x_bd[:,0], [-1,1])\n","        y= np.reshape(x_bd[:,1], [-1,1])\n","        u_bd=np.ones([4*bd_size,1])\n","        for i in range(4*bd_size):\n","          u_bd[i]=-((x[i]**2)+(y[i]**2))/4\n","\n","        #*********************************************************\n","        x_dm= np.float32(x_dm)  \n","        x_bd= np.float32(x_bd)\n","        int_dm= np.float32(int_dm)\n","        f_dm= np.float32(f_dm)\n","        u_bd= np.float32(u_bd)\n","        return(x_dm, f_dm, x_bd, u_bd, int_dm)      ##int_dm=integrand domain\n","\n","\n","    def sample_test(self, test_size, dim):\n","        up= self.up; low= self.low;\n","        #**********************************************************\n","        x_mesh= np.linspace(low, up, self.mesh_size)\n","        mesh= np.meshgrid(x_mesh, x_mesh)\n","        x= np.reshape(mesh[0], [-1,1])\n","        y= np.reshape(mesh[1], [-1,1])\n","        x_dm= np.concatenate((x,y), 1) \n","        #***********************************************************\n","        u_dm=np.ones([65536,1])\n","        for i in range(65536):\n","          u_dm[i]=-((x_dm[i,0]**2)+(x_dm[i,1]**2))/4\n","        #***********************************************************\n","        x_dm= np.float32(x_dm)\n","        u_dm= np.float32(u_dm)\n","        return(mesh, x_dm, u_dm)\n","\n","\n","    def DNN_u(self, x_in, out_size, name, reuse):\n","        h_size= self.u_hidden_size\n","        with tf.variable_scope(name, reuse= reuse):   ##可以让变量有相同命名\n","            hi= tf.layers.dense(x_in, h_size, activation= tf.nn.tanh,    ##tf.layers.dense表示添加一个层，全连接层\n","                                name='input_layer')\n","            hi= tf.layers.dense(hi, h_size, activation= tf.nn.tanh,\n","                                name='input_layer1')\n","            for i in range(self.u_layer):\n","                if i%2==0:\n","                    hi= tf.layers.dense(hi, h_size, activation= tf.nn.softplus,\n","                                        name='h_layer'+str(i))\n","                else:\n","                    hi= tf.sin(tf.layers.dense(hi, h_size), name='h_layer'+str(i))\n","            out= tf.layers.dense(hi, out_size, name='out_layer')\n","        return(out)\n","\n","\n","    def DNN_v(self, x_in, out_size, name, reuse):\n","        h_size= self.v_hidden_size\n","        with tf.variable_scope(name, reuse= reuse):\n","            hi= tf.layers.dense(x_in, h_size, activation= tf.nn.tanh,\n","                                name='input_layer')\n","            hi= tf.layers.dense(hi, h_size, activation= tf.nn.softplus,\n","                                name='input_layer1')\n","            for i in range(self.v_layer):\n","                if i%2==0:\n","                    hi= tf.layers.dense(hi, h_size, activation= tf.nn.softplus,\n","                                                            name='h_layer'+str(i))\n","                else:\n","                    hi= tf.sin(tf.layers.dense(hi, h_size), name='h_layer'+str(i))\n","            out= tf.layers.dense(hi, out_size, name='out_layer')\n","        return(out)\n","\n","\n","    def grad_u(self, x, out_size, name):\n","        #**************************************\n","        # u(x,y)\n","        fun_u= self.DNN_u(x, out_size, name, tf.AUTO_REUSE)   \n","        #*************************************\n","        # grad_u(x,y)\n","        grad_u= tf.gradients(fun_u, x, unconnected_gradients='zero')[0]\n","        return(fun_u, grad_u)\n","\n","\n","    def grad_v(self, x, out_size, name):\n","        #**************************************\n","        # v(x,y)\n","        fun_v= self.DNN_v(x, out_size, name, tf.AUTO_REUSE)\n","        #*************************************\n","        # grad_v(x,y)\n","        grad_v= tf.gradients(fun_v, x, unconnected_gradients='zero')[0]\n","        return(fun_v, grad_v)\n","\n","\n","    def fun_a(self, x):   ##PDE公式中的系数a\n","        #********************************************************\n","        out= 1.0\n","        return(out)\n","\n","\n","    def fun_w(self, x, low=0, up=1.0):    ##phi函数的一部分，phi=w*v，其中w在boundary为0\n","        I1= 0.210987\n","        x_list= tf.split(x, self.dim, 1)\n","        #**************************************************\n","        x_scale_list=[]\n","\n","        for i in range(self.dim):\n","          x_scale= x_list[i]   ##做标准化处理\n","          x_scale_list.append(x_scale)\n","        #*************************************************\n","        z_x_list=[];\n","        for i in range(self.dim):\n","          supp_x= tf.greater(1-tf.abs(x_scale_list[i]), 0) & tf.greater(tf.abs(x_scale_list[i]),0)   ##假设w是距离函数\n","          z_x= tf.where(supp_x, tf.exp(1/(tf.pow(x_scale_list[i], 2)-1))/I1,   ##w在domain内有值，在boundary上为0\n","                     tf.zeros_like(x_scale_list[i]))  \n","          z_x_list.append(z_x)\n","        #***************************************************\n","        w_val= tf.constant(1.0)  ##创建常量\n","        for i in range(self.dim):\n","          w_val= tf.multiply(w_val, z_x_list[i])  #w在domain上有值，在boundary上为0\n","          dw= tf.gradients(w_val, x, unconnected_gradients='zero')[0]\n","          dw= tf.where(tf.is_nan(dw), tf.zeros_like(dw), dw)\n","        return(w_val, dw)\n","\n","\n","    def build(self):\n","        #**************************************************************\n","        with tf.name_scope('placeholder'):\n","            self.x_domain= tf.placeholder(tf.float32, shape=[None, self.dim], name='x_dm')\n","            self.f_obv= tf.placeholder(tf.float32, shape=[None, 1], name='f_obv')\n","            self.x_bound= tf.placeholder(tf.float32, shape=[None, self.dim], name='x_b')\n","            self.g_obv= tf.placeholder(tf.float32, shape=[None, 1], name='g_obv')\n","            self.int_domain= tf.placeholder(tf.float32, shape=(), name='int_domain')\n","        #**************************************************************\n","        name_u= 'dnn_u'; name_v= 'dnn_v';\n","        self.u_val, self.du= self.grad_u(self.x_domain, 1, name_u)\n","        self.v_val, self.dv= self.grad_v(self.x_domain, 1, name_v)\n","        self.w_val, self.dw= self.fun_w(self.x_domain)\n","        u_bound= self.DNN_u(self.x_bound, 1, name_u, tf.AUTO_REUSE)\n","        #\n","        a_val= self.fun_a(self.x_domain)\n","        self.wv= tf.multiply(self.w_val, self.v_val)\n","        #\n","        du_dw= tf.reduce_sum(tf.multiply(self.du, self.dw), axis=1)  \n","        du_dw= tf.reshape(du_dw, [-1,1])\n","        #\n","        du_dv= tf.reduce_sum(tf.multiply(self.du, self.dv), axis=1)\n","        du_dv= tf.reshape(du_dv, [-1,1])\n","        #\n","        du_dwv= tf.add(tf.multiply(self.v_val, du_dw),   ##分部计算dwv，du相当于已知\n","                       tf.multiply(self.w_val, du_dv))\n","        #**************************************************************\n","        with tf.name_scope('loss'):\n","            # \n","            v_norm= tf.multiply(tf.reduce_mean((self.v_val)**2), self.int_domain)  ##phi的2范数的平方，只用了v是因为这里参数更新只与v有关\n","            #\n","            with tf.name_scope('u_loss'):\n","                #\n","                int_l1= tf.multiply(tf.reduce_mean(tf.multiply(\n","                    a_val,du_dwv)), self.int_domain)\n","                int_r= tf.multiply(tf.reduce_mean(\n","                    tf.multiply(self.f_obv, self.wv)), self.int_domain)  \n","                #\n","                int_l1_w= tf.multiply(tf.reduce_mean(tf.multiply(      ##loss_int_w只算了w没有v\n","                    a_val,du_dw)), self.int_domain)\n","                int_r_w= tf.multiply(tf.reduce_mean(\n","                    tf.multiply(self.f_obv, self.w_val)), self.int_domain)\n","                #\n","                self.loss_int= tf.square(int_l1-int_r) / v_norm  \n","                self.loss_int_w= tf.square(int_l1_w-int_r_w)                        \n","                # \n","                self.loss_bound= tf.reduce_sum(tf.abs(u_bound-self.g_obv))   \n","                #\n","                self.loss_u= (50)*self.loss_bound+(1.0)*self.loss_int#+(0.0)*self.loss_int_w      ##为什么loss_int_w系数是0？？？\n","            with tf.name_scope('v_loss'):\n","                self.loss_v=  - tf.log(self.loss_int) \n","        #**************************************************************\n","        # \n","        u_vars= tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='dnn_u')\n","        v_vars= tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='dnn_v')\n","        #***************************************************************\n","        # \n","        with tf.name_scope('optimizer'):\n","            self.u_opt= tf.train.AdagradOptimizer(self.u_rate).minimize(       ##优化\n","                    self.loss_u, var_list= u_vars)\n","            self.v_opt= tf.train.AdagradOptimizer(self.v_rate).minimize(\n","                    self.loss_v, var_list= v_vars)\n","\n","\n","    def train(self):\n","        #****************************************************************\n","        tf.reset_default_graph(); self.build(); \n","        #***************************************************************\n","        mesh, test_x, test_u= self.sample_test(self.test_size, self.dim);    ##sample test函数的输出\n","        step=[]; error_l2r=[]; error_l2=[]; \n","        time_begin=time.time(); time_list=[]; iter_time_list=[]\n","        #***************************************************************\n","        #saver= tf.train.Saver()\n","        with tf.Session() as sess:\n","            sess.run(tf.global_variables_initializer())\n","            #****************************\n","            for i in range(self.iteration):\n","                # mini-batch data\n","                train_data= self.sample_train(self.batch_size, self.bound_size, self.dim)  \n","                feed_train={self.x_domain: train_data[0],    ####feed_dict的作用是给使用placeholder创建出来的tensor赋值\n","                            self.f_obv: train_data[1],\n","                            self.x_bound: train_data[2],\n","                            self.g_obv: train_data[3],\n","                            self.int_domain: train_data[4]}\n","                if i%5==0: \n","                    #*********************************\n","                    pred_u, pred_v= sess.run([self.u_val, self.v_val],feed_dict={self.x_domain: test_x})   ##用test_x得到新的u_val,v_val输出\n","                    err_l2= np.sqrt(np.mean(np.square(test_u-pred_u)))   ##pred_u是按神经网络方法计算得到的u\n","                    u_norm= np.sqrt(np.mean(np.square(test_u)))   ##u的范数吗？？？\n","                    step.append(i+1); \n","                    error_l2r.append(err_l2/u_norm); error_l2.append(err_l2)  ##error_12r比error_12多除了一个u_norm\n","                    time_step= time.time(); time_list.append(time_step-time_begin)            \n","                if i%200==0: \n","                    loss_v, loss_u, int_u, intw_u, loss_bd= sess.run(\n","                        [self.loss_v, self.loss_u, self.loss_int, self.loss_int_w, self.loss_bound], \n","                        feed_dict= feed_train)\n","                    print('Iterations:{}'.format(i))\n","                    print('u_loss:{} v_loss:{}'.format(loss_u, loss_v))\n","                    print('int_u:{} int_u_w:{} loss_bd:{} err_l2r:{}'.format(\n","                        int_u, intw_u, loss_bd, error_l2r[-1]))  ##[-1]取最后一个元素\n","                    #self.show_error(step, error_l2r, self.dim, 'l2r')  ##show error什么意思？？？\n","                    #self.show_v_val(mesh, test_x, pred_v, 'v', i)\n","                    #self.show_u_val(mesh, test_x, test_u, pred_u, 'u', i)\n","                #\n","                iter_time0= time.time()\n","                for _ in range(self.v_step):  ##v_step步长\n","                    _ = sess.run(self.v_opt, feed_dict=feed_train)\n","                for _ in range(self.u_step):\n","                    _ = sess.run(self.u_opt, feed_dict=feed_train)\n","                iter_time_list.append(time.time()-iter_time0)\n","                #\n","            #*******************************************\n","            #self.show_error_abs(mesh, test_x, np.abs(test_u-pred_u), self.dim)\n","            #self.show_u_val(mesh, test_x, test_u, pred_u, 'u', i)\n","            print('L2_e is {}, L2_re is {}'.format(np.min(error_l2), np.min(error_l2r)))\n","            print('Running time is:{}'.format(time_list[-1]))\n","        return(mesh, test_x, test_u, pred_u, step, error_l2, error_l2r, time_list, iter_time_list, self.dim)\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXWolglBlxQQ","executionInfo":{"status":"ok","timestamp":1602856119394,"user_tz":-480,"elapsed":8172189,"user":{"displayName":"Rainie Zhang","photoUrl":"","userId":"00518680448560906167"}},"outputId":"ff84ddea-3267-4711-9b15-df55162a44ba","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__=='__main__':\n","    demo= pde_wan()\n","    mesh, test_x, test_u, pred_u, step, error_l2, error_l2r, time_list, iter_time_list, dim = demo.train()\n","    #***************************\n","    # save data as .mat form\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    import os\n","    os.chdir('/content/drive/My Drive/Colab_Notebooks')\n","    file_path= './problem_data/'   #文件路径为当前运行目录下的/problem_data/\n","\n","    import scipy.io\n","    data_save= {}\n","    data_save['mesh']= mesh  ##是一个list，里面有两个矩阵，矩阵的元素是将domain划分好的x取值点，\n","    data_save['test_x']= test_x  ##在domain内x的取值点，由mesh而来\n","    data_save['test_u']= test_u  ##由test_x得到的u值\n","    data_save['pred_u']= pred_u  ##由test_x通过神经网络得到的u值\n","    data_save['step']= step   ##每隔5次迭代输出的次数\n","    data_save['error_l2']= error_l2   ##test_u,pred_u的差\n","    data_save['error_l2r']= error_l2r   ##比error_12r多除一个u_norm\n","    data_save['time_list']= time_list   ##每5次迭代的总运行时间\n","    data_save['iter_time_list']= iter_time_list  ##每次迭代的总运行时间\n","    scipy.io.savemat(file_path+'tensorflow1_rectangular_plate', data_save)\n","    print('Data saved in '+file_path)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Iterations:0\n","u_loss:21784.083984375 v_loss:-0.291059285402298\n","int_u:1.337843894958496 int_u_w:1.305614709854126 loss_bd:435.6549072265625 err_l2r:5.3667378425598145\n","Iterations:200\n","u_loss:481.8812255859375 v_loss:3.8069732189178467\n","int_u:0.02221531979739666 int_u_w:0.02213660255074501 loss_bd:9.63718032836914 err_l2r:0.21286655962467194\n","Iterations:400\n","u_loss:399.6933898925781 v_loss:2.8527276515960693\n","int_u:0.057686757296323776 int_u_w:0.03009248897433281 loss_bd:7.9927144050598145 err_l2r:0.18609550595283508\n","Iterations:600\n","u_loss:408.1209411621094 v_loss:-0.32916563749313354\n","int_u:1.3898080587387085 int_u_w:0.024208970367908478 loss_bd:8.134622573852539 err_l2r:0.18019478023052216\n","Iterations:800\n","u_loss:400.6744689941406 v_loss:-0.8960170149803162\n","int_u:2.4498260021209717 int_u_w:0.02610190212726593 loss_bd:7.9644927978515625 err_l2r:0.17642946541309357\n","Iterations:1000\n","u_loss:341.39849853515625 v_loss:0.733065664768219\n","int_u:0.4804338812828064 int_u_w:0.027306735515594482 loss_bd:6.818361282348633 err_l2r:0.19039589166641235\n","Iterations:1200\n","u_loss:294.5461120605469 v_loss:-2.2806482315063477\n","int_u:9.783019065856934 int_u_w:0.023935072124004364 loss_bd:5.6952619552612305 err_l2r:0.2315215915441513\n","Iterations:1400\n","u_loss:425.23394775390625 v_loss:-1.5008645057678223\n","int_u:4.485565185546875 int_u_w:0.02886977791786194 loss_bd:8.41496753692627 err_l2r:0.3232513964176178\n","Iterations:1600\n","u_loss:560.0308227539062 v_loss:-3.271765947341919\n","int_u:26.357847213745117 int_u_w:0.027561761438846588 loss_bd:10.673460006713867 err_l2r:0.36398234963417053\n","Iterations:1800\n","u_loss:519.844482421875 v_loss:-1.4107537269592285\n","int_u:4.099043846130371 int_u_w:0.016836103051900864 loss_bd:10.314908981323242 err_l2r:0.3675120174884796\n","Iterations:2000\n","u_loss:351.1588439941406 v_loss:-2.0501222610473633\n","int_u:7.7688517570495605 int_u_w:0.02625753916800022 loss_bd:6.867799758911133 err_l2r:0.3282376825809479\n","Iterations:2200\n","u_loss:406.7811584472656 v_loss:-2.6342265605926514\n","int_u:13.932531356811523 int_u_w:0.023663850501179695 loss_bd:7.856972694396973 err_l2r:0.3409125804901123\n","Iterations:2400\n","u_loss:412.63580322265625 v_loss:-3.3038086891174316\n","int_u:27.216096878051758 int_u_w:0.021324971690773964 loss_bd:7.7083940505981445 err_l2r:0.3413742184638977\n","Iterations:2600\n","u_loss:279.3853759765625 v_loss:-2.1701431274414062\n","int_u:8.759536743164062 int_u_w:0.01606454886496067 loss_bd:5.4125165939331055 err_l2r:0.3182043433189392\n","Iterations:2800\n","u_loss:329.6656188964844 v_loss:-3.470020294189453\n","int_u:32.137393951416016 int_u_w:0.019708458334207535 loss_bd:5.950564384460449 err_l2r:0.32372400164604187\n","Iterations:3000\n","u_loss:350.6968994140625 v_loss:-4.237280368804932\n","int_u:69.2193603515625 int_u_w:0.01646139845252037 loss_bd:5.629550933837891 err_l2r:0.3156338036060333\n","Iterations:3200\n","u_loss:290.9656066894531 v_loss:-2.9194977283477783\n","int_u:18.5319766998291 int_u_w:0.019633639603853226 loss_bd:5.448672294616699 err_l2r:0.320448637008667\n","Iterations:3400\n","u_loss:282.2485046386719 v_loss:-3.721576690673828\n","int_u:41.329505920410156 int_u_w:0.019571933895349503 loss_bd:4.818379878997803 err_l2r:0.3118436932563782\n","Iterations:3600\n","u_loss:288.2137451171875 v_loss:-4.151808261871338\n","int_u:63.54881286621094 int_u_w:0.01734023727476597 loss_bd:4.493298530578613 err_l2r:0.30497801303863525\n","Iterations:3800\n","u_loss:242.9717254638672 v_loss:-3.3884124755859375\n","int_u:29.618896484375 int_u_w:0.023533042520284653 loss_bd:4.267056465148926 err_l2r:0.30454015731811523\n","Iterations:4000\n","u_loss:234.56695556640625 v_loss:-3.935026168823242\n","int_u:51.16348648071289 int_u_w:0.015062847174704075 loss_bd:3.668069362640381 err_l2r:0.29245033860206604\n","Iterations:4200\n","u_loss:279.38739013671875 v_loss:-4.04331636428833\n","int_u:57.015106201171875 int_u_w:0.02345808781683445 loss_bd:4.447445869445801 err_l2r:0.3005630373954773\n","Iterations:4400\n","u_loss:180.11566162109375 v_loss:-3.1073598861694336\n","int_u:22.36193084716797 int_u_w:0.016033045947551727 loss_bd:3.1550745964050293 err_l2r:0.2904364764690399\n","Iterations:4600\n","u_loss:220.57553100585938 v_loss:-3.30184006690979\n","int_u:27.16257095336914 int_u_w:0.027716921642422676 loss_bd:3.8682594299316406 err_l2r:0.2961355447769165\n","Iterations:4800\n","u_loss:269.7582092285156 v_loss:-4.739687919616699\n","int_u:114.39849853515625 int_u_w:0.02309742569923401 loss_bd:3.107194185256958 err_l2r:0.2854849100112915\n","Iterations:5000\n","u_loss:271.68023681640625 v_loss:-4.605066299438477\n","int_u:99.98963165283203 int_u_w:0.024193115532398224 loss_bd:3.433811902999878 err_l2r:0.287611186504364\n","Iterations:5200\n","u_loss:223.89053344726562 v_loss:-4.583364009857178\n","int_u:97.84297180175781 int_u_w:0.015847396105527878 loss_bd:2.52095103263855 err_l2r:0.27109020948410034\n","Iterations:5400\n","u_loss:195.66336059570312 v_loss:-1.8767794370651245\n","int_u:6.532432556152344 int_u_w:0.023732373490929604 loss_bd:3.782618284225464 err_l2r:0.3010055720806122\n","Iterations:5600\n","u_loss:183.9241180419922 v_loss:-3.1698451042175293\n","int_u:23.803796768188477 int_u_w:0.022396685555577278 loss_bd:3.202406406402588 err_l2r:0.2884403169155121\n","Iterations:5800\n","u_loss:181.22007751464844 v_loss:-2.994370937347412\n","int_u:19.97279167175293 int_u_w:0.01477601658552885 loss_bd:3.224945545196533 err_l2r:0.28216326236724854\n","Iterations:6000\n","u_loss:140.3065643310547 v_loss:-2.262664556503296\n","int_u:9.608658790588379 int_u_w:0.016383623704314232 loss_bd:2.6139581203460693 err_l2r:0.24007730185985565\n","Iterations:6200\n","u_loss:173.5059356689453 v_loss:-3.827382802963257\n","int_u:45.942142486572266 int_u_w:0.02028219774365425 loss_bd:2.5512759685516357 err_l2r:0.23668865859508514\n","Iterations:6400\n","u_loss:181.79290771484375 v_loss:-3.989642381668091\n","int_u:54.03556442260742 int_u_w:0.018666910007596016 loss_bd:2.5551469326019287 err_l2r:0.2700643241405487\n","Iterations:6600\n","u_loss:184.35635375976562 v_loss:-4.457779884338379\n","int_u:86.29571533203125 int_u_w:0.015440298244357109 loss_bd:1.9612127542495728 err_l2r:0.24289065599441528\n","Iterations:6800\n","u_loss:127.700927734375 v_loss:-3.4602015018463135\n","int_u:31.82339096069336 int_u_w:0.01441966276615858 loss_bd:1.9175506830215454 err_l2r:0.24445711076259613\n","Iterations:7000\n","u_loss:202.44790649414062 v_loss:-4.195148944854736\n","int_u:66.36360168457031 int_u_w:0.01395490113645792 loss_bd:2.7216861248016357 err_l2r:0.21865853667259216\n","Iterations:7200\n","u_loss:163.78488159179688 v_loss:-3.648925304412842\n","int_u:38.43334197998047 int_u_w:0.012602919712662697 loss_bd:2.507030963897705 err_l2r:0.2531931400299072\n","Iterations:7400\n","u_loss:94.00038146972656 v_loss:-1.4865174293518066\n","int_u:4.421669960021973 int_u_w:0.01309017650783062 loss_bd:1.791574239730835 err_l2r:0.2406531125307083\n","Iterations:7600\n","u_loss:157.35232543945312 v_loss:-3.590050458908081\n","int_u:36.23590850830078 int_u_w:0.008161275647580624 loss_bd:2.422328472137451 err_l2r:0.2419835925102234\n","Iterations:7800\n","u_loss:154.31285095214844 v_loss:-3.2044105529785156\n","int_u:24.640972137451172 int_u_w:0.006701714359223843 loss_bd:2.593437433242798 err_l2r:0.2339756339788437\n","Iterations:8000\n","u_loss:91.21443176269531 v_loss:-0.812472403049469\n","int_u:2.2534725666046143 int_u_w:0.0035088106524199247 loss_bd:1.779219150543213 err_l2r:0.20269934833049774\n","Iterations:8200\n","u_loss:154.16696166992188 v_loss:-1.8273236751556396\n","int_u:6.217225074768066 int_u_w:0.0012120312312617898 loss_bd:2.9589948654174805 err_l2r:0.17577879130840302\n","Iterations:8400\n","u_loss:144.86326599121094 v_loss:-1.172927975654602\n","int_u:3.231440305709839 int_u_w:0.0006232119631022215 loss_bd:2.8326363563537598 err_l2r:0.17200550436973572\n","Iterations:8600\n","u_loss:156.70077514648438 v_loss:-1.3099877834320068\n","int_u:3.7061283588409424 int_u_w:0.00020169676281511784 loss_bd:3.0598928928375244 err_l2r:0.16234107315540314\n","Iterations:8800\n","u_loss:124.78271484375 v_loss:-2.1892166137695312\n","int_u:8.928216934204102 int_u_w:0.00018060831644106656 loss_bd:2.3170900344848633 err_l2r:0.16556763648986816\n","Iterations:9000\n","u_loss:163.39013671875 v_loss:-2.297010660171509\n","int_u:9.944411277770996 int_u_w:2.5813511456362903e-05 loss_bd:3.0689144134521484 err_l2r:0.15496058762073517\n","Iterations:9200\n","u_loss:125.78407287597656 v_loss:-2.83972430229187\n","int_u:17.111047744750977 int_u_w:4.551084930426441e-05 loss_bd:2.1734604835510254 err_l2r:0.15999972820281982\n","Iterations:9400\n","u_loss:135.61602783203125 v_loss:-1.3098182678222656\n","int_u:3.705500364303589 int_u_w:0.0018560175085440278 loss_bd:2.6382102966308594 err_l2r:0.15298934280872345\n","Iterations:9600\n","u_loss:114.92117309570312 v_loss:-1.9609953165054321\n","int_u:7.106396675109863 int_u_w:0.0007352483808062971 loss_bd:2.1562955379486084 err_l2r:0.1515246480703354\n","Iterations:9800\n","u_loss:121.93226623535156 v_loss:0.7856764793395996\n","int_u:0.4558112621307373 int_u_w:0.0010649948380887508 loss_bd:2.4295291900634766 err_l2r:0.14706698060035706\n","Iterations:10000\n","u_loss:97.74191284179688 v_loss:1.6595336198806763\n","int_u:0.190227672457695 int_u_w:0.0015544070629402995 loss_bd:1.951033592224121 err_l2r:0.1472311019897461\n","Iterations:10200\n","u_loss:101.4181900024414 v_loss:-0.16306640207767487\n","int_u:1.1771148443222046 int_u_w:0.0004929029964841902 loss_bd:2.004821538925171 err_l2r:0.1473364382982254\n","Iterations:10400\n","u_loss:92.00243377685547 v_loss:-1.4597104787826538\n","int_u:4.304713249206543 int_u_w:0.0009082856122404337 loss_bd:1.7539544105529785 err_l2r:0.1481551080942154\n","Iterations:10600\n","u_loss:101.8499755859375 v_loss:-1.5196982622146606\n","int_u:4.570845603942871 int_u_w:0.0009287777356803417 loss_bd:1.945582628250122 err_l2r:0.14219073951244354\n","Iterations:10800\n","u_loss:90.18206787109375 v_loss:-1.9134787321090698\n","int_u:6.7766218185424805 int_u_w:0.0013398213777691126 loss_bd:1.6681089401245117 err_l2r:0.14016447961330414\n","Iterations:11000\n","u_loss:109.36373901367188 v_loss:-1.7225308418273926\n","int_u:5.598680019378662 int_u_w:0.0021056272089481354 loss_bd:2.075301170349121 err_l2r:0.131037175655365\n","Iterations:11200\n","u_loss:118.5042953491211 v_loss:-2.7253611087799072\n","int_u:15.261923789978027 int_u_w:0.0028321563731878996 loss_bd:2.064847469329834 err_l2r:0.1276530623435974\n","Iterations:11400\n","u_loss:100.14887237548828 v_loss:0.798572838306427\n","int_u:0.44997069239616394 int_u_w:0.004504416603595018 loss_bd:1.9939779043197632 err_l2r:0.12819497287273407\n","Iterations:11600\n","u_loss:103.8798828125 v_loss:-0.7724196910858154\n","int_u:2.1649985313415527 int_u_w:0.0021507213823497295 loss_bd:2.0342977046966553 err_l2r:0.12768790125846863\n","Iterations:11800\n","u_loss:89.23358154296875 v_loss:-0.814177393913269\n","int_u:2.2573180198669434 int_u_w:0.0029303105548024178 loss_bd:1.739525318145752 err_l2r:0.12935124337673187\n","Iterations:12000\n","u_loss:92.5165786743164 v_loss:-1.72943913936615\n","int_u:5.637491226196289 int_u_w:0.004074119031429291 loss_bd:1.737581729888916 err_l2r:0.1265428364276886\n","Iterations:12200\n","u_loss:93.20435333251953 v_loss:-1.249780297279358\n","int_u:3.4895763397216797 int_u_w:0.005417915526777506 loss_bd:1.7942955493927002 err_l2r:0.12267287820577621\n","Iterations:12400\n","u_loss:105.73130798339844 v_loss:-1.1949666738510132\n","int_u:3.3034474849700928 int_u_w:0.003095051506534219 loss_bd:2.0485572814941406 err_l2r:0.1175537258386612\n","Iterations:12600\n","u_loss:91.56558227539062 v_loss:-1.0334817171096802\n","int_u:2.810835361480713 int_u_w:0.0033882949501276016 loss_bd:1.7750948667526245 err_l2r:0.12219783663749695\n","Iterations:12800\n","u_loss:95.86273193359375 v_loss:-0.9748584032058716\n","int_u:2.650791883468628 int_u_w:0.0039609335362911224 loss_bd:1.8642387390136719 err_l2r:0.11767342686653137\n","Iterations:13000\n","u_loss:89.01976776123047 v_loss:-2.0298802852630615\n","int_u:7.613174915313721 int_u_w:0.005155324470251799 loss_bd:1.6281318664550781 err_l2r:0.11438606679439545\n","Iterations:13200\n","u_loss:81.35638427734375 v_loss:-0.6951124668121338\n","int_u:2.003934383392334 int_u_w:0.00613912520930171 loss_bd:1.587048888206482 err_l2r:0.11197933554649353\n","Iterations:13400\n","u_loss:82.27738189697266 v_loss:-1.0748924016952515\n","int_u:2.929677724838257 int_u_w:0.004098962061107159 loss_bd:1.586954116821289 err_l2r:0.11078797280788422\n","Iterations:13600\n","u_loss:84.45307922363281 v_loss:-1.6022614240646362\n","int_u:4.964245796203613 int_u_w:0.008377079851925373 loss_bd:1.589776635169983 err_l2r:0.110109344124794\n","Iterations:13800\n","u_loss:82.15459442138672 v_loss:-1.0234068632125854\n","int_u:2.782658815383911 int_u_w:0.0050910236313939095 loss_bd:1.587438702583313 err_l2r:0.10727418959140778\n","Iterations:14000\n","u_loss:70.9831771850586 v_loss:-0.603095531463623\n","int_u:1.8277679681777954 int_u_w:0.004847311414778233 loss_bd:1.383108139038086 err_l2r:0.10424621403217316\n","Iterations:14200\n","u_loss:87.77745819091797 v_loss:-2.2108519077301025\n","int_u:9.123486518859863 int_u_w:0.006077447906136513 loss_bd:1.5730793476104736 err_l2r:0.10194671899080276\n","Iterations:14400\n","u_loss:86.90435028076172 v_loss:-2.1989758014678955\n","int_u:9.015775680541992 int_u_w:0.0065714470110833645 loss_bd:1.5577714443206787 err_l2r:0.1003689169883728\n","Iterations:14600\n","u_loss:78.55355834960938 v_loss:-1.35318124294281\n","int_u:3.8697166442871094 int_u_w:0.005817819852381945 loss_bd:1.4936769008636475 err_l2r:0.09831397235393524\n","Iterations:14800\n","u_loss:66.01880645751953 v_loss:-1.5103923082351685\n","int_u:4.528506755828857 int_u_w:0.00460729468613863 loss_bd:1.2298060655593872 err_l2r:0.09862307459115982\n","Iterations:15000\n","u_loss:82.22798156738281 v_loss:-1.6435564756393433\n","int_u:5.17353630065918 int_u_w:0.006233430001884699 loss_bd:1.5410889387130737 err_l2r:0.09590518474578857\n","Iterations:15200\n","u_loss:80.94656372070312 v_loss:-1.5361942052841187\n","int_u:4.646871566772461 int_u_w:0.0037073404528200626 loss_bd:1.525993824005127 err_l2r:0.09308343380689621\n","Iterations:15400\n","u_loss:75.44568634033203 v_loss:-1.5657844543457031\n","int_u:4.786428451538086 int_u_w:0.006632352713495493 loss_bd:1.4131851196289062 err_l2r:0.09334368258714676\n","Iterations:15600\n","u_loss:68.28718566894531 v_loss:-1.1999561786651611\n","int_u:3.3199713230133057 int_u_w:0.007830017246305943 loss_bd:1.2993443012237549 err_l2r:0.09135744720697403\n","Iterations:15800\n","u_loss:66.32246398925781 v_loss:-0.9218044281005859\n","int_u:2.513822317123413 int_u_w:0.008516572415828705 loss_bd:1.2761728763580322 err_l2r:0.09177594631910324\n","Iterations:16000\n","u_loss:74.66930389404297 v_loss:-1.7891409397125244\n","int_u:5.984309673309326 int_u_w:0.010326107032597065 loss_bd:1.3736999034881592 err_l2r:0.08892898261547089\n","Iterations:16200\n","u_loss:65.48184967041016 v_loss:-1.0504140853881836\n","int_u:2.8588345050811768 int_u_w:0.008929901756346226 loss_bd:1.252460241317749 err_l2r:0.08982110768556595\n","Iterations:16400\n","u_loss:69.42350006103516 v_loss:-0.4716910421848297\n","int_u:1.6027021408081055 int_u_w:0.003653361462056637 loss_bd:1.3564159870147705 err_l2r:0.08486509323120117\n","Iterations:16600\n","u_loss:75.62055206298828 v_loss:-1.0246033668518066\n","int_u:2.7859902381896973 int_u_w:0.011468497104942799 loss_bd:1.4566912651062012 err_l2r:0.08319765329360962\n","Iterations:16800\n","u_loss:68.68529510498047 v_loss:-0.6306615471839905\n","int_u:1.8788530826568604 int_u_w:0.009723658673465252 loss_bd:1.336128830909729 err_l2r:0.08228394389152527\n","Iterations:17000\n","u_loss:65.35520935058594 v_loss:-0.784700334072113\n","int_u:2.1917500495910645 int_u_w:0.012443024665117264 loss_bd:1.2632691860198975 err_l2r:0.08064505457878113\n","Iterations:17200\n","u_loss:78.58183288574219 v_loss:-1.3463228940963745\n","int_u:3.8432674407958984 int_u_w:0.008380244486033916 loss_bd:1.4947712421417236 err_l2r:0.07880152761936188\n","Iterations:17400\n","u_loss:73.03529357910156 v_loss:-1.113176941871643\n","int_u:3.044013738632202 int_u_w:0.0090399831533432 loss_bd:1.3998255729675293 err_l2r:0.07585786283016205\n","Iterations:17600\n","u_loss:70.89947509765625 v_loss:-1.2533565759658813\n","int_u:3.5020782947540283 int_u_w:0.011673332192003727 loss_bd:1.3479480743408203 err_l2r:0.07516632229089737\n","Iterations:17800\n","u_loss:72.65980529785156 v_loss:0.01973939873278141\n","int_u:0.98045414686203 int_u_w:0.010319373570382595 loss_bd:1.4335870742797852 err_l2r:0.07442958652973175\n","Iterations:18000\n","u_loss:49.12649154663086 v_loss:-0.630834698677063\n","int_u:1.879178524017334 int_u_w:0.01431923359632492 loss_bd:0.9449462890625 err_l2r:0.07882142066955566\n","Iterations:18200\n","u_loss:74.53071594238281 v_loss:-0.8954644799232483\n","int_u:2.448472738265991 int_u_w:0.01124129630625248 loss_bd:1.4416449069976807 err_l2r:0.07277680188417435\n","Iterations:18400\n","u_loss:74.05854797363281 v_loss:-0.4742155075073242\n","int_u:1.6067532300949097 int_u_w:0.009924592450261116 loss_bd:1.4490360021591187 err_l2r:0.07131670415401459\n","Iterations:18600\n","u_loss:72.02435302734375 v_loss:-0.8182408809661865\n","int_u:2.2665092945098877 int_u_w:0.011674104258418083 loss_bd:1.3951568603515625 err_l2r:0.06979364901781082\n","Iterations:18800\n","u_loss:66.55409240722656 v_loss:-1.3668806552886963\n","int_u:3.9230940341949463 int_u_w:0.008944890461862087 loss_bd:1.252619981765747 err_l2r:0.06840440630912781\n","Iterations:19000\n","u_loss:65.76238250732422 v_loss:-0.8044961094856262\n","int_u:2.235569715499878 int_u_w:0.008598706685006618 loss_bd:1.270536184310913 err_l2r:0.06753446906805038\n","Iterations:19200\n","u_loss:86.67488098144531 v_loss:-0.6559895873069763\n","int_u:1.9270485639572144 int_u_w:0.011371907778084278 loss_bd:1.694956660270691 err_l2r:0.0908709242939949\n","Iterations:19400\n","u_loss:97.36448669433594 v_loss:-0.2324962317943573\n","int_u:1.2617456912994385 int_u_w:0.011524916626513004 loss_bd:1.9220547676086426 err_l2r:0.09151077270507812\n","Iterations:19600\n","u_loss:82.36708068847656 v_loss:-0.49161845445632935\n","int_u:1.6349601745605469 int_u_w:0.010427991859614849 loss_bd:1.6146425008773804 err_l2r:0.08927969634532928\n","Iterations:19800\n","u_loss:70.65711212158203 v_loss:-0.04129436984658241\n","int_u:1.042158842086792 int_u_w:0.01236654818058014 loss_bd:1.3922990560531616 err_l2r:0.06522592157125473\n","Iterations:20000\n","u_loss:72.05911254882812 v_loss:-0.8322765827178955\n","int_u:2.2985455989837646 int_u_w:0.01371640246361494 loss_bd:1.3952113389968872 err_l2r:0.0614381767809391\n","L2_e is 0.012131390161812305, L2_re is 0.061358507722616196\n","Running time is:8062.620310783386\n","Mounted at /content/drive\n","Data saved in ./problem_data/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w5cBcazGFzQv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kJSWdsXFzp3","executionInfo":{"status":"ok","timestamp":1594525464152,"user_tz":-480,"elapsed":974,"user":{"displayName":"Rainie Zhang","photoUrl":"","userId":"00518680448560906167"}},"outputId":"82651818-619a-4ea8-abf3-4870ed89e41d","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["demo=pde_wan()\n","x_domain= np.random.uniform(0, 1, [300, 2])\n","name_u= 'dnn_u'\n","u,du=demo.grad_u(x_domain,1,name_u)\n","print(du)\n","print(u)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensor(\"zeros_like_8:0\", shape=(300, 2), dtype=float64)\n","Tensor(\"dnn_u_8/out_layer/BiasAdd:0\", shape=(300, 1), dtype=float64)\n"],"name":"stdout"}]}]}